==Iespējas==
esošai daudzus engines aptverošai sistēmai pieplagot ClusterPoint
    https://github.com/brianfrankcooper/YCSB
    https://github.com/toflames/Wikipedia-noSQL-Benchmark
        http://www.nosqlbenchmarking.com/2011/03/updated-benchmark-methodology/

Pēc piemēra uztaisīt pamatā Clusterpoint testēšanai savu, kuru vēlāk papildindāt ar interesējošām,
    tātad modulāru,lai var viegli ieplagot citu engine. Piemēri:
        https://github.com/mongodb/mongo-perf
        http://people.apache.org/~mikemccand/lucenebench/
        https://github.com/felixge/couchdb-benchmarks

==Idializēts plāns==
uztaisīt javas moduli priekš CP ko iejūt vienā no esošajiem enginiem
uztaisīt custum python sistēmu, kas tieši CP testē uz mums vajadzīgo visu


==testi==

owerhead tester
    palaiž test run ar visu maksimāli tālu, bet neko nesūta serverim, lai testētu ši gala aizturi

insert
    empty docs
    batches of empty doccs
    inserts docs with fixed field with incermenting integer as value
    insert ~1k prepared docs

update

query

==TODO==

-pamata rāmis
    -pamata arhitektūra
    X -komandrindas parametru/karogu handlings
    -tredu spawnošana,programmēšana,kontrolēšana,beigšana un datu savākšana no tiem
    X -loggers
-tā javas tūļa veidīgi pamata workloads
-datu apkopošana/glabāšana
-datu vizuāla reprezentācija

-nepabeigtie ods and ends/todo punkti
-kārtīga funkcionāla testēšana
-performances testēšana, profilēšana, optimizācija
-vēl testa workloads



javas testera stila prastie testi
    insert in MB/s or ops/s
    R/W load (balanced, R heavy), throuhput in ops/s, latency in s
specifiskki performances test
    dazadi search varianti (laikam ops/s ..  bet noteiktam query setam)


==profiling==
python2 -m cProfile -o remote.prof taskmaster.py -u tcp://192.168.0.185 -n test_storage --debug
runsnake remote.prof


==remote server==
root
password
ip: ... 81




TODU
smukāku standartizētu argumentu padošanu taska init
rezultātu atgriešana
run load sinhrinizēšana
padod vēl papildus parametrus, piemēŗam load pickle argumentam faila vārdu
iespējams parametrus bez connection aprakstošajiem kā konfigurāciju pašā taska?
varbūt taskmaster arī jābūt neatkarīgam procesam?
opts/s ieroebežojums
vai ir vēl parametri,ko vajdzētu dot bench,kas visiem taksiem vajdzīgi?
    kā padod tāska specifiskos?
task un TaskMaster klasēm taisīt base variantus bench.py
    tos tad importēs un inheritos task'u faili, papildinot,owerridojot
        tikai to koa vajaga.
    base task/taskMaster varētu darboties standalone kā vnk tessts,kas 
        sūta status tikai vai tml, un ar -t or smlt slēdzi palaižams.
condition vairāki var izmanto to pašu lock (vs event)
divus alternatīvus piegājiesnus:
    taskmaster liek taskus queue 
    katrs workers neatkarīgi sev ģenerē taskus
partiasit to modulī,ko ar pip importēt (tad python -m bench ...)
vizualizācijai vnk http serveris,kas dod ģenerētus grafikus uz browzeriem?
Eventu vietā kkādu vien shared lauku,kas satur komandu?

jādd kontrole:
    beigt beigt workload
    sākt workload
jādabū stāvoklis
    prep pabeigts


vēl parametri vajadzīgie:
    connection aprakstšie (url lists)
    task name
    paralēlu tasku skaits
    ops/s ierobežojums (task specific?)
    taska specifiska datu faila vārds?



__2__
TIME:    118.67149806
OPS:     23600
AVG LAT: 0.00991603800806
MAX LAT: 1.95279788971
MIN LAT: 0.000932931900024

__200__
TIME:    127.289239168
OPS:     23600
AVG LAT: 1.07279970522
MAX LAT: 127.253911018
MIN LAT: 0.00110793113708

__200__
TIME:    113.552797079
OPS:     4474
AVG LAT: 2.20706451147
MAX LAT: 113.454516888
MIN LAT: 0.00159788131714

__200__
TIME:    113.443348885
OPS:     4296
AVG LAT: 1.09809202788
MAX LAT: 113.43463707
MIN LAT: 0.00136804580688

__200__
TIME:    120.071531057
OPS:     4296
AVG LAT: 4.58600205705
MAX LAT: 120.010153055
MIN LAT: 0.00180506706238



        while True:
            # TODO: conditon lai ieks queue samestos jobus ar ops/s throtletu
            task = self.task_queue.get()
            if task == 'POISON': # Poison!
                self.logger.info('Poisoned!')
                self.task_queue.task_done()
                break
            else:
                start_time = time.time()
                self.connection.insert(task, fully_formed=True)
                end_time = time.time()
                self.result_queue.put(end_time - start_time)
                self.task_queue.task_done()


